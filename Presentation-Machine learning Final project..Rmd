---
title: "Evaluation of Machine learning algorithms for delineating site-specific Management
  Units"
author: "Huma and Wub"
date: "12/8/2020"
output: powerpoint_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


## Library

```{r warning=FALSE, message=FALSE}
library(raster)
library(rgdal)
library (pls)
library(ggplot2)
library(ggfortify)
library(autoplotly)
```

- raster
- rgdal
- pls

## 1. Principal component analysis

- Objective
- To choose the best predictors to delineate management zone

## Data structure

```{r echo=TRUE}
Soil_data_WithG = read.csv("Data_4_machine learning_with_G.csv", quote="'")

colnames(Soil_data_WithG)

#head(Soil_data_WithG)
#str(Soil_data_WithG)
```


## Scaled dataset | PCA

```{r echo=TRUE}
Soil_data_WithG.scaled = scale(as.matrix(Soil_data_WithG[4:13]))

pca = princomp(Soil_data_WithG.scaled,cor=F,scores=T)
summary(pca)
```

## PCA Outputs

```{r echo=TRUE}
#attributes(pca)
pca$loadings
```

## PCA plot

```{r}
biplot(pca)
```

## Study Area

```{r echo=TRUE, warning=FALSE, message=FALSE}
library(rgdal)
Study_area= readOGR("Study_area.shp")
plot(Study_area, asp=1,type='l',xaxt='n',yaxt='n',xlab='',ylab='',bty='n',col='grey')
backdrop = function() 
plot(Study_area,asp=1,type='l',xaxt='n',yaxt='n',xlab='',ylab='',bty='n',col='grey')
```

## PC1

```{r echo=TRUE, warning=FALSE, message=FALSE}
pc1 = pca$scores[,1]
backdrop()
points(Soil_data_WithG$POINT_X[pc1>0],Soil_data_WithG$POINT_Y[pc1>0],pch=16,col='yellow')
points(Soil_data_WithG$POINT_X[pc1<0],Soil_data_WithG$POINT_Y[pc1<0],pch=16,col='brown')
```

## PC2

```{r echo=TRUE, warning=FALSE, message=FALSE}

pc2 = pca$scores[,2]
backdrop()
points(Soil_data_WithG$POINT_X[pc2>0],Soil_data_WithG$POINT_Y[pc2>0],pch=16,col='yellow')
points(Soil_data_WithG$POINT_X[pc2<0],Soil_data_WithG$POINT_Y[pc2<0],pch=16,col='brown')
```

## 2.	K-means clustering to delineate in-season management zone

```{r echo=TRUE, message=FALSE, warning=FALSE}
#Data
NDVI_Data_4_Kmeans = read.csv("Data_4_machine learning_bare_NDVI_SAVI.csv", quote="'")

#Prepare Data
NDVI_K_means_cluster = kmeans(NDVI_Data_4_Kmeans[,4:7], centers = 3, iter.max = 500, nstart = 3, algorithm="Lloyd")
```

## Clustering

```{r echo=TRUE, message=FALSE, warning=FALSE}
#attributes(NDVI_K_means_cluster)
#str(NDVI_K_means_cluster)
cluster_4_NDVI_plot = NDVI_K_means_cluster$cluster
```

## Plot clustering

```{r echo=TRUE, message=FALSE, warning=FALSE}
#plot
plot(Study_area, asp=1,type='l',xaxt='n',yaxt='n',xlab='',ylab='',bty='n',col='grey')
backdrop_1 = function() 
plot(Study_area, asp=1,type='l',xaxt='n',yaxt='n',xlab='',ylab='',bty='n',col='grey')

points(NDVI_Data_4_Kmeans$POINT_X[cluster_4_NDVI_plot==1], NDVI_Data_4_Kmeans$POINT_Y[cluster_4_NDVI_plot==1], pch=16, col='green')
points(NDVI_Data_4_Kmeans$POINT_X[cluster_4_NDVI_plot==2], NDVI_Data_4_Kmeans$POINT_Y[cluster_4_NDVI_plot==2], pch=16, col='blue')
points(NDVI_Data_4_Kmeans$POINT_X[cluster_4_NDVI_plot==3], NDVI_Data_4_Kmeans$POINT_Y[cluster_4_NDVI_plot==3], pch=16, col='red')
```

## 3. Nitrogen prediction based on ECa and VI based

```{r}
N_prediction = read.csv("Data_4_machine learning_PLSR.csv", quote="'")
str(N_prediction)
```

## Linear regression summary

```{r}
N_lm = lm(Nitrate_N ~ Eca_deep + Eca_shallow + Bare_SAVI + Bare_NDVI + DEM , data = N_prediction)
summary(N_lm)
```

## Data Summary

```{r}
summary(N_prediction)
#Many of these predictors are significant
#The r square is 0.7291 for all 5 regresses
```

## Fitted Vs response plot

```{r}
#plot the fitted variables against their response variables >> #To check the scatter and if it's noisy.
plot(N_lm$fitted.values ~ N_prediction$Nitrate_N, main = "fitted vs response")
```

## Partial least square regression

```{r echo=TRUE}
#partial least square
N_plsr = plsr(Nitrate_N ~ Eca_deep + Eca_shallow + Bare_SAVI + Bare_NDVI + DEM , data = N_prediction, scale = TRUE, ncomp =5, validation = "CV")
#validation procedure - standard cross validation
```

## Partial least square regression summary

```{r}
summary(N_plsr)
#shows us the percentage variance explained in our Nitrate N
#plsr mapping a linear combination of x variables and use that to optimize predicting against y variable (N_nitrate)
```

## RMSP plot

```{r}
plot(RMSEP(N_plsr))
```

## Subsetting the dataset into training and testing data

```{r echo=TRUE}
#training and test data
#Split the data into training (60%) and “test” (40%) set randomly.

plsr_data = sample(nrow(N_prediction), nrow(N_prediction)*.6)
plsr_training = N_prediction[plsr_data,]
plsr_test = N_prediction[-plsr_data,]
```

## Training the model

```{r echo=TRUE}
#number of component chosen is 4
#training
N_plsr_training = plsr(Nitrate_N ~ Eca_deep + Eca_shallow + Bare_SAVI + Bare_NDVI + DEM , data = plsr_training, scale = TRUE, ncomp =4)
```

## Training model summary

```{r echo=TRUE}
#validation procedure - standard cross validation
summary(N_plsr_training)
```

## Testing the trained model

```{r echo=TRUE}
#test >>> predict
Predicted_N = predict(N_plsr_training, newdata=plsr_test)
plsr_test$plsr_N_fitted = predict(N_plsr_training, newdata=plsr_test)
```

## How well the nitrate nitrogen predicted accurately?

```{r echo=TRUE}
#R-square need to be calculated to compare the MSE of different models
average_test = mean(plsr_test$Nitrate_N)

1- mean((Predicted_N - plsr_test$Nitrate_N)^2)/mean((average_test - plsr_test$Nitrate_N)^2)

```

## 4. OM prediction based on ECa and VI based

```{r}
OM_prediction = read.csv("Data_4_machine learning_PLSR.csv", quote="'")
str(OM_prediction)
```

## Linear regression summary

```{r}
OM_lm = lm(Nitrate_N ~ Eca_deep + Eca_shallow + Bare_SAVI + Bare_NDVI + DEM , data = OM_prediction)
summary(OM_lm)
```

## Data Summary

```{r}
summary(OM_prediction)
#Many of these predictors are significant
#The r square is 0.7291 for all 5 regresses
```

## Fitted Vs response plot

```{r}
#plot the fitted variables against their response variables >> #To check the scatter and if it's noisy.
plot(OM_lm$fitted.values ~ OM_prediction$OM, main = "fitted vs response")
```

## Partial least square regression

```{r echo=TRUE}
#partial least square
OM_plsr = plsr(OM ~ Eca_deep + Eca_shallow + Bare_SAVI + Bare_NDVI + DEM , data = OM_prediction, scale = TRUE, ncomp =5, validation = "CV")
#validation procedure - standard cross validation
```

## Partial least square regression summary

```{r}
summary(OM_plsr)
#shows us the percentage variance explained in our Nitrate N
#plsr mapping a linear combination of x variables and use that to optimize predicting against y variable (N_nitrate)
```

## RMSP plot

```{r}
plot(RMSEP(OM_plsr))
```

## Subsetting the dataset into training and testing data

```{r echo=TRUE}
#training and test data
#Split the data into training (60%) and “test” (40%) set randomly.

OM_plsr_data = sample(nrow(OM_prediction), nrow(OM_prediction)*.6)
OM_plsr_training = OM_prediction[plsr_data,]
OM_plsr_test = OM_prediction[-plsr_data,]
```

## Training the model

```{r echo=TRUE}
#number of component chosen is 4
#training
OM_plsr_training = plsr(OM ~ Eca_deep + Eca_shallow + Bare_SAVI + Bare_NDVI + DEM , data = OM_plsr_training, scale = TRUE, ncomp =4)
```

## Training model summary

```{r echo=TRUE}
#validation procedure - standard cross validation
summary(OM_plsr_training)
```

## Testing the trained model

```{r echo=TRUE}
#test >>> predict
Predicted_OM = predict(OM_plsr_training, newdata=OM_plsr_test)
OM_plsr_test$plsr_OM_fitted = predict(OM_plsr_training, newdata=OM_plsr_test)
```


## How well the nitrate nitrogen predicted accurately?

```{r echo=TRUE}
#R-square need to be calculated to compare the MSE of different models
average_test_OM = mean(OM_plsr_test$OM)

1- mean((Predicted_OM - OM_plsr_test$OM)^2)/mean((average_test_OM - OM_plsr_test$OM)^2)

```
